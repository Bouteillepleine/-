name: Build OnePlus Kernels with SukiSU Ultra

permissions:
  contents: write

on:
  workflow_dispatch:
    inputs:
      make_release:
        description: 'Create a release?'
        required: true
        type: boolean
        default: false
      op_model:
        description: 'Select kernels to build'
        required: true
        type: choice
        options:
          - ALL
          - android15-6.6
          - android14-6.1
          - android14-5.15
          - android13-5.15
          - android13-5.10
          - android12-5.10
          - OP13-CPH
          - OP13-PJZ
          - OP13r
          - OP13S
          - OP13T
          - OP12
          - OP12r
          - OP11
          - OP11r
          - OP10pro
          - OP10t
          - OP-Nord-5
          - OP-NORD-4
          - OP-NORD-4-CE
          - OP-NORD-CE4-LITE
          - OP-ACE-5-PRO
          - OP-ACE-5
          - OP-ACE-3-PRO
          - OP-ACE-3V
          - OP-ACE-2-PRO
          - OP-ACE-2
          - OP-OPEN
          - OP-PAD-3
          - OP-PAD-2-PRO
          - OP-PAD-2
          - OP-PAD-PRO
        default: ALL
      hook:
        description: 'Hook type'
        required: false
        type: choice
        options: [kprobe, manual, tracepoint]
        default: manual
      lsm:
        description: 'Enable BBG LSM'
        required: false
        type: boolean
        default: false
      enable_zram:
        description: 'Enable ZRAM algorithms'
        required: false
        type: boolean
        default: false
      optimize_level:
        description: 'Optimization level'
        required: false
        type: choice
        options: [O2, O3]
        default: O2

concurrency:
  group: build-${{ github.workflow }}-${{ github.event.inputs.op_model }}
  cancel-in-progress: true

jobs:
  set-op-model:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          sparse-checkout: configs/
          sparse-checkout-cone-mode: false

      - name: Setup Matrix
        id: set-matrix
        shell: bash
        run: |
          set -euo pipefail
          
          [ ! -d "configs" ] && { echo "::error::configs/ not found!"; exit 1; }
          
          # Stable sorted list of configs
          declare -a models=()
          while IFS= read -r -d '' file; do
            models+=("$(basename "$file" .json)")
          done < <(find configs/ -name "*.json" -print0 | sort -z)
          
          [ ${#models[@]} -eq 0 ] && { echo "::error::No configs found!"; exit 1; }
          
          echo "Found ${#models[@]} config(s)"
          
          # Build JSON array
          echo "[" > matrix.json
          first=true
          for model in "${models[@]}"; do
            file="configs/$model.json"
            # Validate JSON and required fields
            jq empty "$file" 2>/dev/null || { echo "::warning::Invalid JSON: $file"; continue; }
            jq -e 'has("model") and has("android_version") and has("kernel_version")' "$file" >/dev/null 2>&1 || { echo "::warning::Missing required fields: $file"; continue; }
            [ "$first" = false ] && echo "," >> matrix.json
            jq -r '.' "$file" >> matrix.json
            first=false
          done
          echo "]" >> matrix.json
          
          # Apply filter based on input
          input="${{ github.event.inputs.op_model }}"
          jq_filter="."
          
          if [[ "$input" == "ALL" ]]; then
            echo "Building all models"
          elif [[ "$input" == android*-* ]]; then
            av="${input%%-*}"
            kv="${input#*-}"
            
            if [ -z "$av" ] || [ -z "$kv" ]; then
              echo "::error::Invalid android-kernel format: $input"
              exit 1
            fi
            
            echo "Filtering: Android=$av, Kernel=$kv"
            jq_filter="map(select(.android_version == \"$av\" and .kernel_version == \"$kv\"))"
          else
            echo "Filtering: Model=$input"
            jq_filter="map(select(.model == \"$input\"))"
          fi
          
          # Apply filter
          filtered=$(jq -c "$jq_filter" matrix.json)
          count=$(echo "$filtered" | jq 'length')
          
          # Validate results
          if [ "$count" -eq 0 ]; then
            echo "::error::No configurations match: $input"
            exit 1
          fi
          
          if [ "$count" -gt 256 ]; then
            echo "::error::Too many configurations ($count > 256)"
            exit 1
          fi
          
          echo "Matched $count configuration(s)"
          
          # Wrap in include object
          wrapped=$(jq -n --argjson items "$filtered" '{ include: $items }')
          
          # Output to GitHub
          {
            echo "matrix<<EOF"
            echo "$wrapped"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"
          
          # Generate summary
          {
            echo "### 📱 Build Matrix"
            echo "**Input:** \`$input\` | **Matched:** $count configuration(s)"
            echo ""
            echo "<details>"
            echo "<summary>View Matrix JSON</summary>"
            echo ""
            echo '```json'
            echo "$wrapped" | jq '.'
            echo '```'
            echo "</details>"
            echo ""
            echo "| # | Model | Android | Kernel |"
            echo "|---|-------|---------|--------|"
            
            echo "$filtered" | jq -r '.[] | "\(.model)|\(.android_version)|\(.kernel_version)"' | \
            awk -F'|' '{printf "| %d | %s | %s | %s |\n", NR, $1, $2, $3}'
          } >> $GITHUB_STEP_SUMMARY

  build:
    name: ${{ matrix.model }}
    needs: set-op-model
    runs-on: ubuntu-latest
    timeout-minutes: 180
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.set-op-model.outputs.matrix) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Generate Cache Keys
        id: cache-keys
        shell: bash
        run: |
          set -euo pipefail
          
          echo "::group::Generate Cache Keys"
          
          # Validate matrix context availability
          MATRIX_JSON='${{ toJSON(matrix) }}'
          if [ "$MATRIX_JSON" = "null" ] || [ -z "$MATRIX_JSON" ]; then
            echo "::warning::No matrix context available, using fallback"
            CONFIG_HASH="nomat"
          else
            CONFIG_HASH=$(printf '%s' "$MATRIX_JSON" | sha256sum | cut -c1-8)
          fi
          
          # Include build inputs in hash
          INPUT_HASH=$(printf '%s-%s-%s-%s' \
            "${{ inputs.hook }}" \
            "${{ inputs.lsm }}" \
            "${{ inputs.enable_zram }}" \
            "${{ inputs.optimize_level }}" | sha256sum | cut -c1-8)
          
          # Guard for clang version (may not be set yet in composite action)
          if [ -n "${{ env.CLANG_VERSION }}" ]; then
            CLANG_SHORT=$(echo "${{ env.CLANG_VERSION }}" | sha256sum | cut -c1-8)
          else
            CLANG_SHORT="noclang"
            echo "::notice::CLANG_VERSION not set yet, using placeholder"
          fi
          
          # Construct cache keys
          CCACHE_KEY="ccache-${{ matrix.model }}-${{ matrix.kernel_version }}-${{ matrix.android_version }}-${CONFIG_HASH}-${INPUT_HASH}-${CLANG_SHORT}"
          
          # Prebuilts key (independent of clang/inputs)
          PREBUILTS_HASH="${{ hashFiles(format('configs/{0}.json', matrix.model)) }}"
          PREBUILTS_KEY="prebuilts-${{ matrix.model }}-${{ matrix.kernel_version }}-${PREBUILTS_HASH}"
          
          echo "ccache_key=$CCACHE_KEY" >> $GITHUB_OUTPUT
          echo "prebuilts_key=$PREBUILTS_KEY" >> $GITHUB_OUTPUT
          
          # Export ccache environment (consistent path)
          CCACHE_DIR="$HOME/.ccache"
          echo "CCACHE_DIR=$CCACHE_DIR" >> $GITHUB_ENV
          echo "CCACHE_MAXSIZE=5G" >> $GITHUB_ENV
          
          echo "Cache keys generated:"
          echo "  Config Hash: $CONFIG_HASH"
          echo "  Input Hash: $INPUT_HASH"
          echo "  Clang Token: $CLANG_SHORT"
          echo "  Ccache Key: $CCACHE_KEY"
          echo "  Prebuilts Key: $PREBUILTS_KEY"
          echo "  Directory: $CCACHE_DIR"
          
          echo "::endgroup::"

      - name: Restore Compiler Cache
        id: cache-ccache-restore
        uses: actions/cache/restore@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ${{ steps.cache-keys.outputs.ccache_key }}
          restore-keys: |
            ccache-${{ matrix.model }}-${{ matrix.kernel_version }}-${{ matrix.android_version }}-
            ccache-${{ matrix.model }}-${{ matrix.kernel_version }}-
            ccache-${{ matrix.model }}-
          enableCrossOsArchive: false

      - name: Configure Ccache
        shell: bash
        run: |
          set -euo pipefail
          
          echo "::group::Configure Ccache"
          
          CCACHE_DIR="${{ env.CCACHE_DIR }}"
          mkdir -p "$CCACHE_DIR"
          
          if ! command -v ccache >/dev/null 2>&1; then
            echo "::warning::ccache not found, compilation will be slower"
            echo "::endgroup::"
            exit 0
          fi
          
          # Set maximum size
          ccache -M "${{ env.CCACHE_MAXSIZE }}"
          
          # ============================================
          # CENTRALIZED CONFIGURATION (single source of truth)
          # ============================================
          
          # Compiler check: 'content' is safer than 'none'
          ccache -o compiler_check=content
          
          # Consolidate sloppiness settings (single point of control)
          ccache -o sloppiness=file_macro,time_macros,include_file_mtime,include_file_ctime
          
          # Performance optimizations
          ccache -o max_files=0          # No file count limit, only size
          ccache -o hash_dir=false        # Don't hash current directory
          ccache -o compression=true      # Enable compression
          ccache -o compression_level=1   # Fast compression
          
          # Show final configuration
          echo "Ccache configuration:"
          ccache -p | grep -E '(max_size|compiler_check|sloppiness|hash_dir|compression)' || ccache -p
          
          # Show initial state (DON'T reset stats with -z for cumulative tracking)
          echo ""
          echo "Initial ccache state:"
          ccache -s
          
          # Show cache directory info
          echo ""
          echo "Cache directory: $CCACHE_DIR"
          echo "Owner: $(stat -c '%U:%G' "$CCACHE_DIR" 2>/dev/null || echo 'N/A')"
          
          CACHE_SIZE=$(du -sh "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "0")
          echo "Size: $CACHE_SIZE"
          
          # Determine restore status
          if [ "${{ steps.cache-ccache-restore.outputs.cache-hit }}" = "true" ]; then
            echo ""
            echo "✅ Exact cache hit"
          elif [ -n "${{ steps.cache-ccache-restore.outputs.cache-matched-key }}" ]; then
            echo ""
            echo "🔄 Partial cache hit: ${{ steps.cache-ccache-restore.outputs.cache-matched-key }}"
          else
            echo ""
            echo "❌ Cold cache start"
          fi
          
          echo "::endgroup::"

      - name: Restore Prebuilts Cache
        id: cache-prebuilts-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            ${{ matrix.model }}/kernel_platform/prebuilts
            ${{ matrix.model }}/kernel_platform/prebuilts-master
          key: ${{ steps.cache-keys.outputs.prebuilts_key }}
          restore-keys: |
            prebuilts-${{ matrix.model }}-${{ matrix.kernel_version }}-
            prebuilts-${{ matrix.model }}-
          enableCrossOsArchive: false

      - name: Cache Debug Info
        shell: bash
        run: |
          echo "::group::Cache Restore Status"
          echo "Ccache Hit: ${{ steps.cache-ccache-restore.outputs.cache-hit }}"
          echo "Ccache Matched Key: ${{ steps.cache-ccache-restore.outputs.cache-matched-key || 'none' }}"
          echo "Prebuilts Hit: ${{ steps.cache-prebuilts-restore.outputs.cache-hit }}"
          echo "Prebuilts Matched Key: ${{ steps.cache-prebuilts-restore.outputs.cache-matched-key || 'none' }}"
          echo ""
          
          if [ -d "${{ env.CCACHE_DIR }}" ]; then
            echo "Ccache size: $(du -sh ${{ env.CCACHE_DIR }} 2>/dev/null | awk '{print $1}' || echo '0')"
          else
            echo "Ccache: not restored (cold start)"
          fi
          
          if [ -d "${{ matrix.model }}/kernel_platform/prebuilts" ]; then
            echo "Prebuilts size: $(du -sh ${{ matrix.model }}/kernel_platform/prebuilts 2>/dev/null | awk '{print $1}' || echo '0')"
          else
            echo "Prebuilts: not restored (will download)"
          fi
          echo "::endgroup::"

      - name: Build Kernel
        id: build
        uses: ./.github/actions
        with:
          op_config_json: ${{ toJSON(matrix) }}
          ksu_meta: 'susfs-main/⚡Ultra⚡/'
          hook: ${{ inputs.hook }}
          lsm: ${{ inputs.lsm }}
          enable_zram: ${{ inputs.enable_zram }}
          optimize_level: ${{ inputs.optimize_level }}
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Validate Outputs
        if: always()
        shell: bash
        run: |
          missing=0
          for out in kernel_version sukisu_version susfs_version image_sha256 warnings_count zip_name zip_size zip_sha256; do
            case "$out" in
              kernel_version) v="${{ steps.build.outputs.kernel_version }}" ;;
              sukisu_version) v="${{ steps.build.outputs.sukisu_version }}" ;;
              susfs_version) v="${{ steps.build.outputs.susfs_version }}" ;;
              image_sha256) v="${{ steps.build.outputs.image_sha256 }}" ;;
              warnings_count) v="${{ steps.build.outputs.warnings_count }}" ;;
              zip_name) v="${{ steps.build.outputs.zip_name }}" ;;
              zip_size) v="${{ steps.build.outputs.zip_size }}" ;;
              zip_sha256) v="${{ steps.build.outputs.zip_sha256 }}" ;;
            esac
            if [ -z "${v:-}" ]; then
              echo "::error::Missing: $out"; ((missing++))
            else
              if [ "$out" = "warnings_count" ] && ! [[ "$v" =~ ^[0-9]+$ ]]; then
                echo "::error::warnings_count not numeric: $v"; ((missing++))
              else
                echo "✅ $out"
              fi
            fi
          done
          [ $missing -gt 0 ] && exit 1 || exit 0

      - name: Ccache Statistics
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          
          if ! command -v ccache >/dev/null 2>&1; then
            echo "ccache not available"
            exit 0
          fi
          
          export CCACHE_DIR="${{ env.CCACHE_DIR }}"
          
          echo "::group::Final Ccache Statistics"
          ccache -s
          echo "::endgroup::"
          
          # ============================================
          # HARDENED STATISTICS PARSING
          # ============================================
          
          STATS_OUTPUT=$(ccache -s 2>/dev/null || echo "")
          
          # Extract hit rate with robust parsing
          CACHE_HIT_RATE=$(echo "$STATS_OUTPUT" | awk -F': ' '
            /cache hit rate/ {
              # Remove percentage sign and whitespace
              gsub(/%/, "", $2)
              gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2)
              print $2
            }
          ')
          [ -z "$CACHE_HIT_RATE" ] && CACHE_HIT_RATE="N/A"
          
          # Extract numeric values with fallback to 0
          DIRECT_HITS=$(echo "$STATS_OUTPUT" | awk -F': ' '
            /cache hit \(direct\)/ {
              gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2)
              print $2
            }
          ' | awk '{print $1}')
          [ -z "$DIRECT_HITS" ] || ! [[ "$DIRECT_HITS" =~ ^[0-9]+$ ]] && DIRECT_HITS=0
          
          PREPROCESSED_HITS=$(echo "$STATS_OUTPUT" | awk -F': ' '
            /cache hit \(preprocessed\)/ {
              gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2)
              print $2
            }
          ' | awk '{print $1}')
          [ -z "$PREPROCESSED_HITS" ] || ! [[ "$PREPROCESSED_HITS" =~ ^[0-9]+$ ]] && PREPROCESSED_HITS=0
          
          CACHE_MISSES=$(echo "$STATS_OUTPUT" | awk -F': ' '
            /cache miss/ {
              gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2)
              print $2
            }
          ' | awk '{print $1}')
          [ -z "$CACHE_MISSES" ] || ! [[ "$CACHE_MISSES" =~ ^[0-9]+$ ]] && CACHE_MISSES=0
          
          # Safe arithmetic (guaranteed numeric)
          TOTAL_HITS=$((DIRECT_HITS + PREPROCESSED_HITS))
          TOTAL_CALLS=$((TOTAL_HITS + CACHE_MISSES))
          
          # Get cache size
          CACHE_SIZE=$(du -sh "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "N/A")
          CACHE_SIZE_BYTES=$(du -s "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "0")
          
          # Get file count
          FILE_COUNT=$(find "$CCACHE_DIR" -type f 2>/dev/null | wc -l || echo "0")
          
          # Determine cache status
          if [ "${{ steps.cache-ccache-restore.outputs.cache-hit }}" = "true" ]; then
            CACHE_STATUS="✅ Exact match"
          elif [ -n "${{ steps.cache-ccache-restore.outputs.cache-matched-key }}" ]; then
            CACHE_STATUS="🔄 Partial match"
          else
            CACHE_STATUS="❌ Cold start"
          fi
          
          # Export for summary (all values guaranteed safe)
          echo "CACHE_HIT_RATE=$CACHE_HIT_RATE" >> $GITHUB_ENV
          echo "CACHE_SIZE=$CACHE_SIZE" >> $GITHUB_ENV
          echo "CACHE_SIZE_BYTES=$CACHE_SIZE_BYTES" >> $GITHUB_ENV
          echo "CACHE_STATUS=$CACHE_STATUS" >> $GITHUB_ENV
          echo "TOTAL_HITS=$TOTAL_HITS" >> $GITHUB_ENV
          echo "CACHE_MISSES=$CACHE_MISSES" >> $GITHUB_ENV
          echo "TOTAL_CALLS=$TOTAL_CALLS" >> $GITHUB_ENV
          echo "FILE_COUNT=$FILE_COUNT" >> $GITHUB_ENV
          
          echo ""
          echo "📊 Cache Performance:"
          echo "   Status: $CACHE_STATUS"
          echo "   Hit Rate: $CACHE_HIT_RATE%"
          echo "   Hits: $TOTAL_HITS"
          echo "   Misses: $CACHE_MISSES"
          echo "   Total Calls: $TOTAL_CALLS"
          echo "   Cache Size: $CACHE_SIZE"
          echo "   File Count: $FILE_COUNT"

      - name: Check Ccache Before Save
        id: ccache-present
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          
          CCACHE_DIR="${{ env.CCACHE_DIR }}"
          
          # Validate directory exists
          if [ ! -d "$CCACHE_DIR" ]; then
            echo "present=false" >> $GITHUB_OUTPUT
            echo "⚠️ Cache directory doesn't exist"
            exit 0
          fi
          
          SIZE=$(du -s "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "0")
          FILE_COUNT=$(find "$CCACHE_DIR" -type f 2>/dev/null | wc -l || echo "0")
          
          echo "Cache size: ${SIZE} KB"
          echo "File count: ${FILE_COUNT}"
          
          # Thresholds: at least 1MB (1024 KB) and 10 files
          MIN_SIZE=1024
          MIN_FILES=10
          
          if [ "$SIZE" -gt "$MIN_SIZE" ] && [ "$FILE_COUNT" -gt "$MIN_FILES" ]; then
            echo "present=true" >> $GITHUB_OUTPUT
            echo "✅ Cache has content, will save"
            echo "   Size: $(numfmt --to=iec-i --suffix=B $((SIZE * 1024)) 2>/dev/null || echo "${SIZE} KB")"
            echo "   Files: $FILE_COUNT"
          else
            echo "present=false" >> $GITHUB_OUTPUT
            echo "⚠️ Cache is empty or too small"
            echo "   Size: ${SIZE} KB (minimum: ${MIN_SIZE} KB)"
            echo "   Files: ${FILE_COUNT} (minimum: ${MIN_FILES})"
            echo "   Skipping save to avoid overwriting good cache"
          fi

      - name: Check Prebuilts Before Save
        id: prebuilts-present
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          
          PREBUILTS_DIR="${{ matrix.model }}/kernel_platform/prebuilts-master"
          
          if [ ! -d "$PREBUILTS_DIR" ]; then
            echo "present=false" >> $GITHUB_OUTPUT
            echo "⚠️ Prebuilts directory doesn't exist"
            exit 0
          fi
          
          # Check if directory has any files
          FILE_COUNT=$(find "$PREBUILTS_DIR" -type f 2>/dev/null | head -1 | wc -l || echo "0")
          
          if [ "$FILE_COUNT" -gt 0 ]; then
            echo "present=true" >> $GITHUB_OUTPUT
            echo "✅ Prebuilts directory has content"
            
            SIZE=$(du -sh "$PREBUILTS_DIR" 2>/dev/null | awk '{print $1}' || echo "N/A")
            echo "   Size: $SIZE"
          else
            echo "present=false" >> $GITHUB_OUTPUT
            echo "⚠️ Prebuilts directory is empty"
          fi

      - name: Save Compiler Cache
        if: always() && steps.ccache-present.outputs.present == 'true'
        uses: actions/cache/save@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ${{ steps.cache-keys.outputs.ccache_key }}-${{ github.run_id }}-${{ github.run_attempt }}

      - name: Save Prebuilts Cache
        if: always() && steps.prebuilts-present.outputs.present == 'true' && steps.cache-prebuilts-restore.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: |
            ${{ matrix.model }}/kernel_platform/prebuilts
            ${{ matrix.model }}/kernel_platform/prebuilts-master
          key: ${{ steps.cache-keys.outputs.prebuilts_key }}

      - name: Build Summary
        if: always()
        shell: bash
        run: |
          status="${{ job.status }}"
          [ "$status" = "success" ] && emoji="✅" || emoji="❌"
          
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## $emoji ${{ matrix.model }} - $status
          
          | Property | Value |
          |----------|-------|
          | Kernel | ${{ steps.build.outputs.kernel_version }} |
          | SukiSU | ${{ steps.build.outputs.sukisu_version }} |
          | SUSFS | ${{ steps.build.outputs.susfs_version }} |
          | Warnings | ${{ steps.build.outputs.warnings_count }} |
          | Package | \`${{ steps.build.outputs.zip_name }}\` |
          | Size | $(numfmt --to=iec-i --suffix=B ${{ steps.build.outputs.zip_size }} 2>/dev/null || echo "${{ steps.build.outputs.zip_size }}") |
          
          **Config:** Hook=\`${{ inputs.hook }}\` LSM=\`${{ inputs.lsm }}\` ZRAM=\`${{ inputs.enable_zram }}\` Opt=\`${{ inputs.optimize_level }}\`
          
          ### 📊 Cache Performance
          
          #### Restore
          - **Status:** ${{ env.CACHE_STATUS }}
          - **Restored Key:** \`${{ steps.cache-ccache-restore.outputs.cache-matched-key || 'none' }}\`
          
          #### Build Statistics
          - **Hit Rate:** ${{ env.CACHE_HIT_RATE }}%
          - **Cache Hits:** ${{ env.TOTAL_HITS }}
          - **Cache Misses:** ${{ env.CACHE_MISSES }}
          - **Total Calls:** ${{ env.TOTAL_CALLS }}
          - **Cache Size:** ${{ env.CACHE_SIZE }}
          - **File Count:** ${{ env.FILE_COUNT }}
          
          #### Save
          - **Ccache:** $([ "${{ steps.ccache-present.outputs.present }}" = "true" ] && echo "✅ Saved" || echo "⏭️ Skipped (empty/small)")
          - **Prebuilts:** $([ "${{ steps.cache-prebuilts-restore.outputs.cache-hit }}" = "true" ] && echo "⏭️ Skipped (exact hit)" || ([ "${{ steps.prebuilts-present.outputs.present }}" = "true" ] && echo "✅ Saved" || echo "⏭️ Skipped (empty)"))
          EOF

      - name: Upload Artifacts
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: kernel-${{ matrix.model }}-${{ matrix.android_version }}-${{ matrix.kernel_version }}
          path: |
            ${{ matrix.model }}/artifacts/${{ steps.build.outputs.zip_name }}
            ${{ matrix.model }}/artifacts/build_info.txt
          retention-days: 7
          compression-level: 0
          if-no-files-found: error

      - name: Cleanup on Cancel
        if: cancelled()
        shell: bash
        run: |
          echo "::warning::Build cancelled for ${{ matrix.model }}"
          
          rm -rf "${{ matrix.model }}/artifacts" "${{ matrix.model }}/out" "${{ matrix.model }}/downloads" || true
          
          if [ -d "${{ matrix.model }}/kernel_platform" ]; then
            find "${{ matrix.model }}/kernel_platform" -mindepth 1 -maxdepth 1 \
              ! -name "prebuilts" ! -name "prebuilts-master" \
              -exec rm -rf {} + 2>/dev/null || true
          fi
          
          echo "✅ Cleanup completed (cache preserved)"

  release:
    needs: build
    runs-on: ubuntu-latest
    if: ${{ inputs.make_release }}
    permissions:
      contents: write
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      RELEASE_NAME: 'OnePlus Kernels - SukiSU Ultra & SUSFS v1.5.2+'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
  
      - name: Install Required Tools
        shell: bash
        run: |
          echo "::group::Installing tools"
          sudo apt-get update -qq
          sudo apt-get install -y -qq jq unzip dos2unix
          echo "::endgroup::"
          
          echo "Installed versions:"
          jq --version
          unzip -v | head -2
          dos2unix --version 2>&1 | head -1
  
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./all-artifacts
          merge-multiple: false
        continue-on-error: false
  
      - name: Assert Artifacts Downloaded
        shell: bash
        run: |
          echo "::group::Validating artifact download"
          
          if [ ! -d ./all-artifacts ] || ! find ./all-artifacts -type f -print -quit | grep -q .; then
            echo "::error::No artifacts were downloaded from the build job"
            echo ""
            echo "This means:"
            echo "  1. All build matrix jobs failed (check build job status)"
            echo "  2. Upload Artifacts step didn't run (verify if: success() condition)"
            echo "  3. Artifacts expired (check retention-days setting)"
            echo "  4. Build job was skipped entirely"
            echo ""
            echo "Directory status:"
            ls -la . || true
            ls -la ./all-artifacts 2>/dev/null || echo "  ./all-artifacts does not exist"
            echo ""
            echo "💡 Tip: Check the build job logs and ensure at least one device built successfully"
            exit 1
          fi
          
          echo "✅ Artifacts directory exists and contains files"
          echo "::endgroup::"
  
      - name: List Downloaded Artifacts
        shell: bash
        run: |
          echo "::group::Downloaded Artifacts Structure"
          
          artifact_dirs=$(find ./all-artifacts -mindepth 1 -maxdepth 1 -type d 2>/dev/null | wc -l | tr -d '[:space:]')
          zip_count=$(find ./all-artifacts -type f -name "*.zip" 2>/dev/null | wc -l | tr -d '[:space:]')
          info_count=$(find ./all-artifacts -type f -name "build_info.txt" 2>/dev/null | wc -l | tr -d '[:space:]')
          
          echo "Summary:"
          echo "  - Artifact directories: $artifact_dirs"
          echo "  - ZIP files: $zip_count"
          echo "  - Build info files: $info_count"
          echo ""
          
          if [ "$artifact_dirs" -gt 0 ]; then
            echo "Directory structure:"
            ls -la ./all-artifacts
            echo ""
          fi
          
          if [ "$zip_count" -gt 0 ] || [ "$info_count" -gt 0 ]; then
            echo "Files (first 50):"
            find ./all-artifacts -type f \( -name "*.zip" -o -name "build_info.txt" \) | head -50
          fi
          
          echo "::endgroup::"
  
      - name: Check gh CLI
        shell: bash
        run: |
          gh --version || { 
            echo "::error::GitHub CLI (gh) not found on runner"
            exit 1
          }
  
      - name: Generate Tag
        shell: bash
        run: |
          set -euo pipefail
          
          BASE_VERSION="v1.5.2"
          
          echo "::group::Fetching existing releases"
          LATEST=$(gh release list \
            --repo "${{ github.repository }}" \
            --limit 300 \
            --json tagName \
            --jq '[.[] | select(.tagName | startswith("'"$BASE_VERSION"'-r")) | .tagName] | sort_by(split("-r")[1] | tonumber) | .[-1]' \
            2>/dev/null || echo "")
          echo "::endgroup::"
          
          if [ -z "$LATEST" ]; then
            NEW_TAG="${BASE_VERSION}-r0"
            echo "No existing tags found, starting with: $NEW_TAG"
          else
            REV=$(echo "$LATEST" | sed -n 's/.*-r\([0-9]\+\)$/\1/p')
            if [ -z "$REV" ]; then
              echo "::error::Failed to parse revision from: $LATEST"
              exit 1
            fi
            NEW_TAG="${BASE_VERSION}-r$((REV + 1))"
            echo "Latest tag: $LATEST (rev $REV)"
            echo "New tag: $NEW_TAG"
          fi
          
          echo "NEW_TAG=$NEW_TAG" >> $GITHUB_ENV
          echo "📌 Tag to be created: $NEW_TAG"
          
          if [[ "$NEW_TAG" =~ (alpha|beta|rc|test|dev|pre) ]]; then
            echo "IS_PRERELEASE=true" >> $GITHUB_ENV
            echo "🔬 Detected as prerelease"
          else
            echo "IS_PRERELEASE=false" >> $GITHUB_ENV
            echo "🎯 Detected as stable release"
          fi
  
      - name: Organize Assets
        shell: bash
        run: |
          #!/usr/bin/env bash
          set -euo pipefail
          
          echo "::group::Organizing Artifacts"
          
          # ============================================
          # HELPER FUNCTIONS
          # ============================================
          
          log_error() {
              echo "::error::$1"
              exit 1
          }
          
          log_warning() {
              echo "::warning::$1"
          }
          
          # Enhanced safe_filename with guaranteed non-empty output
          safe_filename() {
              local filename="$1"
              local out
              
              # Remove unsafe characters, trim leading/trailing dots/dashes
              out="$(echo "$filename" | tr -cs '[:alnum:]._-' '_' | sed -E 's/^[._-]+|[._-]+$//g' | cut -c1-255)"
              
              # Guarantee non-empty result
              if [ -z "$out" ]; then
                  out="artifact"
              fi
              
              printf '%s\n' "$out"
          }
          
          # Helper: Split filename into base and extension safely
          split_filename() {
              local fname="$1"
              local base ext
              
              # Check if filename contains a dot (and it's not a hidden file starting with dot)
              if [[ "$fname" == *.* ]] && [[ "$fname" != .* ]]; then
                  base="${fname%.*}"
                  ext="${fname##*.}"
                  
                  # Ensure extension is not the same as base (no-dot case)
                  if [ "$ext" = "$base" ]; then
                      base="$fname"
                      ext=""
                  fi
              else
                  base="$fname"
                  ext=""
              fi
              
              printf '%s\n%s\n' "$base" "$ext"
          }
          
          log_file_processing() {
              local type="$1"
              local filename="$2"
              local dest="$3"
              echo "[${type^^}] Processing: $filename -> $(basename "$dest")"
          }
          
          # ============================================
          # PRE-FLIGHT CHECKS
          # ============================================
          
          mkdir -p ./all-artifacts ./release-assets || log_error "Failed to create directories"
          [ -d ./all-artifacts ] || log_error "all-artifacts directory does not exist"
          
          # Normalize permissions
          chmod -R u+rwX ./release-assets 2>/dev/null || true
          
          # Ensure release-assets is writable
          touch ./release-assets/.write-test 2>/dev/null && rm -f ./release-assets/.write-test || \
              log_error "Directory ./release-assets is not writable"
          
          # Verify find and sort are available
          command -v find >/dev/null 2>&1 || log_error "find command not found"
          command -v sort >/dev/null 2>&1 || log_error "sort command not found"
          
          # Count total files to process
          total_zips=$(find ./all-artifacts -type f -name "*.zip" 2>/dev/null | wc -l)
          total_infos=$(find ./all-artifacts -type f -name "build_info.txt" 2>/dev/null | wc -l)
          total_files=$((total_zips + total_infos))
          
          echo "📊 Total files to process: $total_files (${total_zips} ZIPs, ${total_infos} build_info.txt)"
          
          if [ "$total_files" -eq 0 ]; then
              log_error "No artifacts found to process!"
          fi
          
          echo ""
          
          declare -i zip_count=0
          declare -i info_count=0
          declare -i skipped_count=0
          
          # ============================================
          # PROCESS ZIP FILES
          # ============================================
          
          while IFS= read -r -d '' zip; do
              [ -f "$zip" ] && [ -r "$zip" ] || { log_warning "Skipping unreadable zip file: $zip"; continue; }
          
              filename=$(basename -- "$zip")
              safe_name=$(safe_filename "$filename")
              
              # Fallback for empty sanitized name
              if [ -z "$safe_name" ]; then
                  safe_name="artifact_$(date +%s).zip"
                  log_warning "Empty filename after sanitization, using fallback: $safe_name"
              fi
              
              dest="./release-assets/$safe_name"
              
              # Initial collision avoidance
              counter=1
              while [ -e "$dest" ]; do
                  read -r base ext < <(split_filename "$safe_name")
                  if [ -n "$ext" ]; then
                      dest="./release-assets/${base}_${counter}.${ext}"
                  else
                      dest="./release-assets/${safe_name}_${counter}"
                  fi
                  ((counter++))
              done
          
              # === SOFT CAP: Truncate if path > 200 chars ===
              if [ ${#dest} -gt 200 ]; then
                  read -r base ext < <(split_filename "$safe_name")
                  
                  # Truncate base to 150 chars
                  base="${base:0:150}"
                  
                  # Reconstruct filename
                  if [ -n "$ext" ]; then
                      safe_name="${base}.${ext}"
                  else
                      safe_name="$base"
                  fi
                  
                  dest="./release-assets/$safe_name"
                  log_warning "Path too long (${#dest} chars), truncated to: $(basename "$dest")"
                  
                  # Re-check for collisions after truncation
                  counter=1
                  while [ -e "$dest" ]; do
                      if [ -n "$ext" ]; then
                          dest="./release-assets/${base}_${counter}.${ext}"
                      else
                          dest="./release-assets/${base}_${counter}"
                      fi
                      ((counter++))
                  done
              fi
          
              # === HARD CAP: Last-resort shortening if still > 260 chars ===
              if [ ${#dest} -gt 260 ]; then
                  short="artifact_$(date +%s%N | cut -c1-13)"
                  dest="./release-assets/${short}.zip"
                  log_warning "Destination path exceeded hard limit (${#dest} chars); forced name: $(basename "$dest")"
                  
                  # Ensure uniqueness for forced name
                  counter=1
                  while [ -e "$dest" ]; do
                      dest="./release-assets/${short}_${counter}.zip"
                      ((counter++))
                  done
              fi
          
              # === COPY WITH VALIDATION ===
              if ! cp -v "$zip" "$dest"; then
                  log_warning "Failed to copy ZIP (skipping): $zip → $dest"
                  ((skipped_count++))
                  continue
              fi
              
              # Verify destination exists and has content
              if [ ! -f "$dest" ] || [ ! -s "$dest" ]; then
                  log_warning "Destination file missing/empty after copy (skipping): $dest"
                  rm -f "$dest" 2>/dev/null || true  # Clean up partial file
                  ((skipped_count++))
                  continue
              fi
          
              log_file_processing "zip" "$filename" "$dest"
              ((zip_count++))
          
          done < <(LC_ALL=C find ./all-artifacts -type f -name "*.zip" -print0 2>/dev/null | LC_ALL=C sort -z)
          
          # ============================================
          # PROCESS BUILD INFO FILES
          # ============================================
          
          while IFS= read -r -d '' info; do
              [ -s "$info" ] && [ -r "$info" ] || { log_warning "Skipping empty/unreadable build info: $info"; continue; }
              dos2unix -q "$info" 2>/dev/null || true
          
              artifact_dir=$(dirname -- "$info")
              dir_name=$(basename -- "$artifact_dir")
          
              # Extract model name with fallback chain
              model=""
              extraction_patterns=(
                  '^kernel-(.+)-android([0-9]+)-([0-9.]+)$'
                  '^kernel-(.+)-android([0-9]+)$'
                  '^kernel-(.+)$'
              )
              for pattern in "${extraction_patterns[@]}"; do
                  if [[ "$dir_name" =~ $pattern ]]; then
                      model="${BASH_REMATCH[1]}"
                      break
                  fi
              done
              
              # Fallback: extract from file content
              if [ -z "$model" ]; then
                  model=$(grep -m1 '^Model:' "$info" 2>/dev/null | cut -d: -f2- | xargs | tr -s '[:space:]' '_' | tr -cd '[:alnum:]_.-' || true)
              fi
              
              # Sanitize and limit length
              model=$(safe_filename "${model:-unknown}" | cut -c1-100)
              
              # Guarantee non-empty model
              if [ -z "$model" ] || [ "$model" = "unknown" ]; then
                  model="unknown_$(date +%s)"
                  log_warning "Could not extract model from: $dir_name; using fallback: $model"
              fi
          
              dest="./release-assets/build_info_${model}.txt"
              
              # Collision avoidance
              counter=1
              while [ -e "$dest" ]; do
                  dest="./release-assets/build_info_${model}_${counter}.txt"
                  ((counter++))
              done
          
              # === SOFT CAP: Truncate if path > 200 chars ===
              if [ ${#dest} -gt 200 ]; then
                  model="${model:0:80}"  # Truncate model name
                  dest="./release-assets/build_info_${model}.txt"
                  log_warning "Path too long, truncated model to: $model"
                  
                  # Re-check for collisions
                  counter=1
                  while [ -e "$dest" ]; do
                      dest="./release-assets/build_info_${model}_${counter}.txt"
                      ((counter++))
                  done
              fi
          
              # === HARD CAP: Last-resort shortening ===
              if [ ${#dest} -gt 260 ]; then
                  short="info_$(date +%s%N | cut -c1-13)"
                  dest="./release-assets/${short}.txt"
                  log_warning "Destination path exceeded hard limit; forced name: $(basename "$dest")"
                  
                  counter=1
                  while [ -e "$dest" ]; do
                      dest="./release-assets/${short}_${counter}.txt"
                      ((counter++))
                  done
              fi
          
              # === COPY WITH VALIDATION ===
              if ! cp -v "$info" "$dest"; then
                  log_warning "Failed to copy build info (skipping): $info → $dest"
                  ((skipped_count++))
                  continue
              fi
              
              # Verify destination exists
              if [ ! -f "$dest" ]; then
                  log_warning "Destination file missing after copy (skipping): $dest"
                  rm -f "$dest" 2>/dev/null || true
                  ((skipped_count++))
                  continue
              fi
          
              log_file_processing "info" "$info" "$dest"
              ((info_count++))
          
          done < <(LC_ALL=C find ./all-artifacts -type f -name "build_info.txt" -print0 2>/dev/null | LC_ALL=C sort -z)
          
          echo "::endgroup::"
          
          # ============================================
          # FINAL SUMMARY
          # ============================================
          
          echo ""
          echo "═══════════════════════════════════════════════════════════════"
          echo "📊 ORGANIZATION SUMMARY"
          echo "═══════════════════════════════════════════════════════════════"
          echo "✅ ZIP files processed:        $zip_count"
          echo "📄 Build info files processed:  $info_count"
          echo "⚠️  Files skipped (errors):     $skipped_count"
          echo "═══════════════════════════════════════════════════════════════"
          
          # Fail if no files were successfully processed
          if [ "$zip_count" -eq 0 ] && [ "$info_count" -eq 0 ]; then
              log_error "No files were successfully processed! Check logs above for errors."
          fi
          
          # Warn if some files were skipped
          if [ "$skipped_count" -gt 0 ]; then
              log_warning "$skipped_count file(s) were skipped due to errors"
          fi
          
          # List final contents
          echo ""
          echo "📦 Final release assets:"
          ls -lh ./release-assets/ || log_error "Failed to list release assets"
          
          echo ""
          echo "✅ Asset organization completed successfully!"
  
      - name: Generate Release Notes
        shell: bash
        run: |
          set -euo pipefail
          
          cat << 'EOF' > notes.md
          # 🚀 SukiSU Ultra with SUSFS v1.5.2+
          
          **SUSFS Module:** https://github.com/sidex15/susfs4ksu-module (v1.5.2+ branch)  
          **SukiSU Manager:** https://github.com/SukiSU-Ultra/SukiSU-Ultra  
          **SUSFS Kernel:** https://gitlab.com/simonpunk/susfs4ksu  
          
          ## 📱 Built Devices
          
          | Device | Kernel | Android | SukiSU | SUSFS | Status |
          |--------|--------|---------|--------|-------|--------|
          EOF
          
          device_count=0
          while IFS= read -r -d '' info; do
            model=$(basename "$info" | sed 's/build_info_\(.*\)\.txt/\1/')
            
            kernel_ver=$(grep "^Kernel Version:" "$info" 2>/dev/null | cut -d: -f2- | xargs || echo "?")
            android_ver=$(grep "^Android Version:" "$info" 2>/dev/null | cut -d: -f2- | xargs || echo "?")
            sukisu_ver=$(grep "^SukiSU Version:" "$info" 2>/dev/null | cut -d: -f2- | xargs || echo "?")
            susfs_ver=$(grep "^SUSFS Version:" "$info" 2>/dev/null | cut -d: -f2- | xargs || echo "?")
            
            zip_file=$(find ./release-assets -type f -name "*${model}*.zip" 2>/dev/null | head -1)
            
            if [ -n "$zip_file" ] && [ -f "$zip_file" ] && unzip -l "$zip_file" 2>/dev/null | grep -q "ksu_module_susfs"; then
              status="✅"
            else
              status="⚠️"
            fi
            
            printf "| %-12s | %-18s | %-8s | %-8s | %-8s | %s |\n" \
              "$model" "$kernel_ver" "$android_ver" "$sukisu_ver" "$susfs_ver" "$status" >> notes.md
            
            ((device_count++))
          done < <(find ./release-assets -name "build_info_*.txt" -type f -print0 2>/dev/null | sort -z)
          
          if [ "$device_count" -eq 0 ]; then
            echo "| *No builds completed* | - | - | - | - | ❌ |" >> notes.md
          fi
          
          cat << 'EOF' >> notes.md
  
          ## ✨ Features
          - ⚡ **SukiSU Ultra Manager** (Latest from susfs-main branch)
          - 🛡️ **SUSFS v1.5.2+** (Kernel patches + KSU module included)
          - 🔐 Magic Mount support
          - 🔒 WireGuard VPN support
          - 🚀 BBR TCP congestion control
          - 🐛 Ptrace fix for kernels <5.16
          - 🎯 Flexible hook types (Manual/Kprobe/Tracepoint)
          - 💾 ZRAM with advanced compressors (LZ4K, LZ4KD, 842)
          - ⚙️ BBG LSM (Baseband Guard)
          - 🔧 Optimized builds (O2/O3)
          
          ## 📦 What's Included
          Each kernel ZIP contains:
          - ✅ Kernel Image with SukiSU Ultra & SUSFS patches
          - ✅ SUSFS KSU Module (v1.5.2+ from CI)
          - ✅ AnyKernel3 flasher (ready to flash)
          - ✅ All necessary tools and scripts
          
          ## 📥 Installation
          1. Download the **AnyKernel3 ZIP** for your device (flashable package)
          2. Flash via **Kernel Flasher** or **SukiSU Ultra Manager** (to enable KPM)
          3. Reboot to system
          4. Verify SUSFS is active (see below)
                    
          ## ⚙️ Build Configuration
          - Hook: `${{ inputs.hook }}`
          - LSM: `${{ inputs.lsm }}`
          - ZRAM: `${{ inputs.enable_zram }}`
          - Optimization: `${{ inputs.optimize_level }}`
          
          ## 🔍 Verification
          After flashing, verify SUSFS is active:
          ```bash
          su -c "dmesg | grep -i susfs"
          ```
          
          You should see SUSFS initialization messages.
          
          ## ⚠️ Legend
          - ✅ = SUSFS module confirmed in package
          - ⚠️ = SUSFS module missing (verify before flashing)
          
          ---
          **Build Date:** $(date -u '+%Y-%m-%d %H:%M UTC')  
          **Build Run:** #${{ github.run_number }}  
          **Commit:** ${{ github.sha }}  
          **Workflow:** ${{ github.workflow }}
          EOF
          
          printf '\n' >> notes.md
          
          echo "Generated release notes for $device_count device(s)"
          
          echo "::group::Release Notes Preview"
          cat notes.md
          echo "::endgroup::"
  
      - name: Create Release with Assets
        shell: bash
        run: |
          set -euo pipefail
          
          echo "::group::Preparing release"
          
          if [ "${{ env.IS_PRERELEASE }}" = "true" ]; then
            PRERELEASE_FLAG="--prerelease"
            echo "Creating as prerelease"
          else
            PRERELEASE_FLAG="--latest"
            echo "Creating as latest stable release"
          fi
          
          ASSETS=()
          while IFS= read -r -d '' file; do
            ASSETS+=("$file")
          done < <(find ./release-assets -type f \( -name "*.zip" -o -name "build_info_*.txt" \) -print0 2>/dev/null | sort -z)
          
          if [ ${#ASSETS[@]} -eq 0 ]; then
            echo "::error::No assets found to upload!"
            exit 1
          fi
          
          echo "Found ${#ASSETS[@]} asset(s) to upload:"
          printf '  - %s\n' "${ASSETS[@]}"
          
          echo "::endgroup::"
          
          for attempt in 1 2 3; do
            echo "::group::Attempt $attempt/3: Creating release ${{ env.NEW_TAG }}"
            
            if gh release create "${{ env.NEW_TAG }}" \
              --repo "${{ github.repository }}" \
              --title "${{ env.RELEASE_NAME }} (${{ env.NEW_TAG }})" \
              --notes-file notes.md \
              --target "${{ github.sha }}" \
              $PRERELEASE_FLAG \
              "${ASSETS[@]}"; then
              
              echo "::endgroup::"
              echo "✅ Release created successfully!"
              exit 0
            fi
            
            echo "::endgroup::"
            echo "⚠️ Attempt $attempt failed"
            
            if [ $attempt -lt 3 ]; then
              sleep_time=$(( (RANDOM % (attempt * 5)) + attempt * 3 ))
              echo "Retrying in ${sleep_time}s..."
              sleep $sleep_time
            fi
          done
          
          echo "::error::Failed to create release after 3 attempts"
          exit 1
  
      - name: Verify Release
        if: success()
        shell: bash
        run: |
          set -euo pipefail
          
          echo "::group::Verifying release ${{ env.NEW_TAG }}"
          
          sleep 3
          
          RELEASE_INFO=$(gh release view "${{ env.NEW_TAG }}" \
            --repo "${{ github.repository }}" \
            --json tagName,name,url,assets,isDraft,isPrerelease,createdAt)
          
          ASSET_COUNT=$(echo "$RELEASE_INFO" | jq '.assets | length')
          ZIPS=$(echo "$RELEASE_INFO" | jq '[.assets[] | select(.name | endswith(".zip"))] | length')
          IS_DRAFT=$(echo "$RELEASE_INFO" | jq -r '.isDraft')
          IS_PRERELEASE=$(echo "$RELEASE_INFO" | jq -r '.isPrerelease')
          RELEASE_URL=$(echo "$RELEASE_INFO" | jq -r '.url')
          CREATED_AT=$(echo "$RELEASE_INFO" | jq -r '.createdAt')
          
          echo "Release Details:"
          echo "  Tag: ${{ env.NEW_TAG }}"
          echo "  URL: $RELEASE_URL"
          echo "  Total Assets: $ASSET_COUNT"
          echo "  ZIP Assets: $ZIPS"
          echo "  Draft: $IS_DRAFT"
          echo "  Prerelease: $IS_PRERELEASE"
          echo "  Created: $CREATED_AT"
          
          if [ "$ASSET_COUNT" -eq 0 ]; then
            echo "::error::No assets found in release!"
            exit 1
          fi
          
          if [ "$ZIPS" -eq 0 ]; then
            echo "::error::Release has no .zip assets!"
            exit 1
          fi
          
          echo ""
          echo "Uploaded Assets:"
          echo "$RELEASE_INFO" | jq -r '.assets[] | "  - \(.name) (\(.size | tonumber | (. / 1048576 | floor))MB)"'
          
          echo "::endgroup::"
          echo "✅ Release verified successfully with $ZIPS kernel ZIP(s)!"
  
      - name: Release Summary
        if: always()
        shell: bash
        run: |
          status="${{ job.status }}"
          [ "$status" = "success" ] && emoji="✅" || emoji="❌"
          
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # $emoji Release: ${NEW_TAG:-N/A}
          
          **Status:** $status  
          **Type:** $([ "${{ env.IS_PRERELEASE }}" = "true" ] && echo "Prerelease 🔬" || echo "Stable 🎯")  
          EOF
          
          if [ "$status" = "success" ] && [ -n "${NEW_TAG:-}" ]; then
            echo "**URL:** https://github.com/${{ github.repository }}/releases/tag/$NEW_TAG" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## 📦 Assets" >> $GITHUB_STEP_SUMMARY
            
            gh release view "$NEW_TAG" \
              --repo "${{ github.repository }}" \
              --json assets \
              --jq '.assets[] | "- `\(.name)` (\((.size | tonumber) / 1048576 | floor)MB)"' \
              >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "- Could not fetch asset list" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## ⚠️ Release Failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ -d ./release-assets ]; then
              echo "**Assets that were prepared:**" >> $GITHUB_STEP_SUMMARY
              find ./release-assets -name "*.zip" -type f 2>/dev/null | sort | while read -r f; do
                filename=$(basename "$f")
                size_bytes=$(stat -c%s "$f" 2>/dev/null || echo "0")
                size_mb=$((size_bytes / 1048576))
                
                if unzip -l "$f" 2>/dev/null | grep -q "ksu_module_susfs"; then
                  status_icon="✅"
                else
                  status_icon="⚠️"
                fi
                
                echo "- $status_icon \`$filename\` (${size_mb}MB)" >> $GITHUB_STEP_SUMMARY
              done || echo "- No assets found" >> $GITHUB_STEP_SUMMARY
            else
              echo "No assets were prepared (check earlier steps)" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          
          ## 🔧 Configuration
          | Setting | Value |
          |---------|-------|
          | Hook | `${{ inputs.hook }}` |
          | LSM | `${{ inputs.lsm }}` |
          | ZRAM | `${{ inputs.enable_zram }}` |
          | Optimization | `${{ inputs.optimize_level }}` |
          
          **Legend:** ✅ = SUSFS module included | ⚠️ = SUSFS module missing

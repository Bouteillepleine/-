name: Build OnePlus Kernels with SukiSU Ultra

permissions:
  contents: write

on:
  workflow_dispatch:
    inputs:
      make_release:
        description: 'Create a release?'
        required: true
        type: boolean
        default: false
      op_model:
        description: 'Select kernels to build'
        required: true
        type: choice
        options:
          - ALL
          - android15-6.6
          - android14-6.1
          - android14-5.15
          - android13-5.15
          - android13-5.10
          - android12-5.10
          - OP13-CPH
          - OP13-PJZ
          - OP13r
          - OP13S
          - OP13T
          - OP12
          - OP12r
          - OP11
          - OP11r
          - OP10pro
          - OP10t
          - OP-Nord-5
          - OP-NORD-4
          - OP-NORD-4-CE
          - OP-NORD-CE4-LITE
          - OP-ACE-5-PRO
          - OP-ACE-5
          - OP-ACE-3-PRO
          - OP-ACE-3V
          - OP-ACE-2-PRO
          - OP-ACE-2
          - OP-OPEN
          - OP-PAD-3
          - OP-PAD-2-PRO
          - OP-PAD-2
          - OP-PAD-PRO
        default: ALL
      hook:
        description: 'Hook type'
        required: false
        type: choice
        options: [kprobe, manual, tracepoint]
        default: manual
      lsm:
        description: 'Enable BBG LSM'
        required: false
        type: boolean
        default: false
      enable_zram:
        description: 'Enable ZRAM algorithms'
        required: false
        type: boolean
        default: false
      optimize_level:
        description: 'Optimization level'
        required: false
        type: choice
        options: [O2, O3]
        default: O2

concurrency:
  group: build-${{ github.workflow }}-${{ github.event.inputs.op_model }}
  cancel-in-progress: true

jobs:
  set-op-model:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          sparse-checkout: configs/
          sparse-checkout-cone-mode: false

      - name: Ensure jq
        shell: bash
        run: |
          if ! command -v jq >/dev/null 2>&1; then
            echo "Installing jq..."
            sudo apt-get update -qq
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y -qq jq
            echo "jq installed: $(jq --version)"
          else
            echo "jq already available: $(jq --version)"
          fi

      - name: Setup Matrix
        id: set-matrix
        shell: bash
        run: |
          set -euo pipefail
          [ ! -d "configs" ] && { echo "::error::configs/ not found!"; exit 1; }

          declare -a models=()
          while IFS= read -r -d '' file; do
            models+=("$(basename "$file" .json)")
          done < <(find configs/ -name "*.json" -print0 | sort -z)
          [ ${#models[@]} -eq 0 ] && { echo "::error::No configs found!"; exit 1; }

          echo "[" > matrix.json
          first=true
          for model in "${models[@]}"; do
            file="configs/$model.json"
            jq empty "$file" 2>/dev/null || { echo "::warning::Invalid JSON: $file"; continue; }
            jq -e 'has("model") and has("android_version") and has("kernel_version")' "$file" >/dev/null 2>&1 || { echo "::warning::Missing required fields: $file"; continue; }
            [ "$first" = false ] && echo "," >> matrix.json
            jq -r '.' "$file" >> matrix.json
            first=false
          done
          echo "]" >> matrix.json

          input="${{ github.event.inputs.op_model }}"
          jq_filter="."
          if [[ "$input" == "ALL" ]]; then
            echo "Building all models"
          elif [[ "$input" == android*-* ]]; then
            av="${input%%-*}"
            kv="${input#*-}"
            if [ -z "$av" ] || [ -z "$kv" ]; then
              echo "::error::Invalid android-kernel format: $input"
              exit 1
            fi
            echo "Filtering: Android=$av, Kernel=$kv"
            jq_filter="map(select(.android_version == \"$av\" and .kernel_version == \"$kv\"))"
          else
            echo "Filtering: Model=$input"
            jq_filter="map(select(.model == \"$input\"))"
          fi

          filtered=$(jq -c "$jq_filter" matrix.json)
          count=$(echo "$filtered" | jq 'length')
          [ "$count" -eq 0 ] && { echo "::error::No configurations match: $input"; exit 1; }
          [ "$count" -gt 256 ] && { echo "::error::Too many configurations ($count > 256)"; exit 1; }

          wrapped=$(jq -n --argjson items "$filtered" '{ include: $items }')
          {
            echo "matrix<<EOF"
            echo "$wrapped"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

          {
            echo "### 📱 Build Matrix"
            echo "**Input:** \`$input\` | **Matched:** $count configuration(s)"
            echo ""
            echo "<details><summary>View Matrix JSON</summary>"
            echo ""
            echo '```json'
            echo "$wrapped" | jq '.'
            echo '```'
            echo "</details>"
            echo ""
            echo "| # | Model | Android | Kernel |"
            echo "|---|-------|---------|--------|"
            echo "$filtered" | jq -r '.[] | "\(.model)|\(.android_version)|\(.kernel_version)"' | \
            awk -F'|' '{printf "| %d | %s | %s | %s |\n", NR, $1, $2, $3}'
          } >> $GITHUB_STEP_SUMMARY

  build:
    name: ${{ matrix.model }}
    needs: set-op-model
    runs-on: ubuntu-latest
    timeout-minutes: 180
    strategy:
      fail-fast: false
      max-parallel: 26
      matrix: ${{ fromJSON(needs.set-op-model.outputs.matrix) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Generate Cache Keys
        id: cache-keys
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Generate Cache Keys"

          MODEL="${{ matrix.model }}"
          KERNEL_VER="${{ matrix.kernel_version }}"
          ANDROID_VER="${{ matrix.android_version }}"
          SOC="${{ matrix.soc }}"
          BRANCH="${{ matrix.branch }}"
          MANIFEST="${{ matrix.manifest }}"

          for field in MODEL KERNEL_VER ANDROID_VER SOC BRANCH MANIFEST; do
            if [ -z "${!field}" ]; then
              echo "::error::Missing required matrix field: $field"
              exit 1
            fi
          done

          CONFIG_STRING=$(printf '%s|%s|%s|%s|%s|%s' \
            "$ANDROID_VER" "$BRANCH" "$KERNEL_VER" "$MANIFEST" "$MODEL" "$SOC" | \
            tr -cd '[:alnum:]|._-')
          CONFIG_HASH=$(printf '%s' "$CONFIG_STRING" | sha256sum | cut -c1-8)

          INPUT_HASH=$(printf '%s-%s-%s-%s' \
            "${{ inputs.hook }}" \
            "${{ inputs.lsm }}" \
            "${{ inputs.enable_zram }}" \
            "${{ inputs.optimize_level }}" | sha256sum | cut -c1-8)

          CACHE_VERSION="v3"

          # Base key for restore (shared among identical configs)
          CCACHE_BASE="ccache-${MODEL}-${KERNEL_VER}-${ANDROID_VER}-${CONFIG_HASH}-${INPUT_HASH}-${CACHE_VERSION}"

          # Unique save key per job (prevents parallel save collisions)
          JOB_SUFFIX="${{ github.run_id }}-${{ strategy.job-index }}"
          CCACHE_SAVE="${CCACHE_BASE}-${JOB_SUFFIX}"

          # Prebuilts key stays stable per device/config
          PREBUILTS_KEY="prebuilts-${MODEL}-${KERNEL_VER}-${ANDROID_VER}-${CONFIG_HASH}"

          echo "ccache_restore_key=$CCACHE_BASE" >> "$GITHUB_OUTPUT"
          echo "ccache_save_key=$CCACHE_SAVE" >> "$GITHUB_OUTPUT"
          echo "prebuilts_key=$PREBUILTS_KEY" >> "$GITHUB_OUTPUT"

          CCACHE_DIR="$HOME/.ccache"
          echo "CCACHE_DIR=$CCACHE_DIR" >> "$GITHUB_ENV"
          echo "CCACHE_MAXSIZE=5G" >> "$GITHUB_ENV"

          echo "Generated Keys:"
          echo "  Restore: $CCACHE_BASE"
          echo "  Save: $CCACHE_SAVE"
          echo "  Prebuilts: $PREBUILTS_KEY"
          echo "  Cache Dir: $CCACHE_DIR"
          echo "::endgroup::"

      - name: Restore Compiler Cache
        id: cache-ccache-restore
        uses: actions/cache/restore@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ${{ steps.cache-keys.outputs.ccache_restore_key }}
          restore-keys: |
            ccache-${{ matrix.model }}-${{ matrix.kernel_version }}-${{ matrix.android_version }}-
            ccache-${{ matrix.model }}-${{ matrix.kernel_version }}-
            ccache-${{ matrix.model }}-
          enableCrossOsArchive: false

      - name: Install ccache
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v ccache >/dev/null 2>&1; then
            sudo apt-get update -qq
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y -qq ccache
            command -v ccache >/dev/null 2>&1 || { echo "::error::Failed to install ccache"; exit 1; }
            echo "ccache installed: $(ccache --version | head -1)"
          else
            echo "ccache already available: $(ccache --version | head -1)"
          fi

      - name: Configure Ccache
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Configure Ccache"
          CCACHE_DIR="${{ env.CCACHE_DIR }}"
          mkdir -p "$CCACHE_DIR"

          if ! command -v ccache >/dev/null 2>&1; then
            echo "::warning::ccache not found, compilation will be slower"
            echo "::endgroup::"
            exit 0
          fi

          ccache -M "${{ env.CCACHE_MAXSIZE }}"
          ccache -o compiler_check=content
          ccache -o sloppiness=file_macro,time_macros,include_file_mtime,include_file_ctime
          ccache -o max_files=0
          ccache -o hash_dir=false
          ccache -o compression=true
          ccache -o compression_level=1

          echo "Ccache configuration (full):"
          ccache -p || true

          echo ""
          echo "Initial ccache state:"
          ccache -s

          echo ""
          echo "Cache directory: $CCACHE_DIR"
          echo "Owner: $(stat -c '%U:%G' "$CCACHE_DIR" 2>/dev/null || echo 'N/A')"
          CACHE_SIZE=$(du -sh "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "0")
          echo "Size: $CACHE_SIZE"

          if [ "${{ steps.cache-ccache-restore.outputs.cache-hit }}" = "true" ]; then
            echo "Exact cache hit"
          elif [ -n "${{ steps.cache-ccache-restore.outputs.cache-matched-key }}" ]; then
            echo "Partial cache hit: ${{ steps.cache-ccache-restore.outputs.cache-matched-key }}"
          else
            echo "Cold cache start"
          fi
          echo "::endgroup::"

      - name: Persist Ccache Config
        shell: bash
        env:
          CCACHE_MAXSIZE: ${{ env.CCACHE_MAXSIZE }}
        run: |
          set -euo pipefail
          CCACHE_DIR="${{ env.CCACHE_DIR }}"
          mkdir -p "$CCACHE_DIR"
          cat > "$CCACHE_DIR/ccache.conf" <<EOF
          max_size = ${CCACHE_MAXSIZE}
          compiler_check = content
          sloppiness = file_macro,time_macros,include_file_mtime,include_file_ctime
          hash_dir = false
          compression = true
          compression_level = 1
          hard_link = true
          EOF
          echo "Wrote $CCACHE_DIR/ccache.conf"
          echo ""
          echo "Effective configuration (full):"
          ccache -p || true

      - name: Ensure prebuilts paths
        shell: bash
        run: |
          mkdir -p "${{ matrix.model }}/kernel_platform/prebuilts" \
                   "${{ matrix.model }}/kernel_platform/prebuilts-master"

      - name: Restore Prebuilts Cache
        id: cache-prebuilts-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            ${{ matrix.model }}/kernel_platform/prebuilts
            ${{ matrix.model }}/kernel_platform/prebuilts-master
          key: ${{ steps.cache-keys.outputs.prebuilts_key }}
          restore-keys: |
            prebuilts-${{ matrix.model }}-${{ matrix.kernel_version }}-
            prebuilts-${{ matrix.model }}-
          enableCrossOsArchive: false

      - name: Cache Debug Info
        shell: bash
        run: |
          echo "::group::Cache Restore Status"
          echo "Restore Key: ${{ steps.cache-keys.outputs.ccache_restore_key }}"
          echo "Save Key: ${{ steps.cache-keys.outputs.ccache_save_key }}"
          echo "Ccache Hit: ${{ steps.cache-ccache-restore.outputs.cache-hit }}"
          echo "Ccache Matched Key: ${{ steps.cache-ccache-restore.outputs.cache-matched-key || 'none' }}"
          echo "Prebuilts Hit: ${{ steps.cache-prebuilts-restore.outputs.cache-hit }}"
          echo "Prebuilts Matched Key: ${{ steps.cache-prebuilts-restore.outputs.cache-matched-key || 'none' }}"
          echo ""
          if [ -d "${{ env.CCACHE_DIR }}" ]; then
            echo "Ccache size: $(du -sh ${{ env.CCACHE_DIR }} 2>/dev/null | awk '{print $1}' || echo '0')"
          else
            echo "Ccache: not restored (cold start)"
          fi
          if [ -d "${{ matrix.model }}/kernel_platform/prebuilts" ]; then
            echo "Prebuilts size: $(du -sh ${{ matrix.model }}/kernel_platform/prebuilts 2>/dev/null | awk '{print $1}' || echo '0')"
          else
            echo "Prebuilts: not restored (will download)"
          fi
          echo "::endgroup::"

      - name: Build Kernel
        id: build
        uses: ./.github/actions
        with:
          op_config_json: ${{ toJSON(matrix) }}
          ksu_meta: 'susfs-main/⚡Ultra⚡/'
          hook: ${{ inputs.hook }}
          lsm: ${{ inputs.lsm }}
          enable_zram: ${{ inputs.enable_zram }}
          optimize_level: ${{ inputs.optimize_level }}
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Validate Outputs
        if: always()
        shell: bash
        run: |
          missing=0
          for out in kernel_version sukisu_version susfs_version image_sha256 warnings_count zip_name zip_size zip_sha256; do
            case "$out" in
              kernel_version) v="${{ steps.build.outputs.kernel_version }}" ;;
              sukisu_version) v="${{ steps.build.outputs.sukisu_version }}" ;;
              susfs_version) v="${{ steps.build.outputs.susfs_version }}" ;;
              image_sha256) v="${{ steps.build.outputs.image_sha256 }}" ;;
              warnings_count) v="${{ steps.build.outputs.warnings_count }}" ;;
              zip_name) v="${{ steps.build.outputs.zip_name }}" ;;
              zip_size) v="${{ steps.build.outputs.zip_size }}" ;;
              zip_sha256) v="${{ steps.build.outputs.zip_sha256 }}" ;;
            esac
            if [ -z "${v:-}" ]; then
              echo "::error::Missing: $out"; ((missing++))
            else
              if [ "$out" = "warnings_count" ] && ! [[ "$v" =~ ^[0-9]+$ ]]; then
                echo "::error::warnings_count not numeric: $v"; ((missing++))
              else
                echo "OK: $out"
              fi
            fi
          done
          [ $missing -gt 0 ] && exit 1 || exit 0

      - name: Ccache Statistics
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v ccache >/dev/null 2>&1; then
            echo "ccache not available"
            exit 0
          fi
          export CCACHE_DIR="${{ env.CCACHE_DIR }}"
          echo "::group::Final Ccache Statistics"
          ccache -s
          echo "::endgroup::"
          STATS_OUTPUT=$(ccache -s 2>/dev/null || echo "")
          CACHE_HIT_RATE=$(echo "$STATS_OUTPUT" | awk -F': ' '/cache hit rate/ {gsub(/%/, "", $2); gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2); print $2}')
          [ -z "$CACHE_HIT_RATE" ] && CACHE_HIT_RATE="N/A"
          DIRECT_HITS=$(echo "$STATS_OUTPUT" | awk -F': ' '/cache hit \(direct\)/ {gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2); print $2}' | awk '{print $1}')
          [ -z "$DIRECT_HITS" ] || ! [[ "$DIRECT_HITS" =~ ^[0-9]+$ ]] && DIRECT_HITS=0
          PREPROCESSED_HITS=$(echo "$STATS_OUTPUT" | awk -F': ' '/cache hit \(preprocessed\)/ {gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2); print $2}' | awk '{print $1}')
          [ -z "$PREPROCESSED_HITS" ] || ! [[ "$PREPROCESSED_HITS" =~ ^[0-9]+$ ]] && PREPROCESSED_HITS=0
          CACHE_MISSES=$(echo "$STATS_OUTPUT" | awk -F': ' '/cache miss/ {gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2); print $2}' | awk '{print $1}')
          [ -z "$CACHE_MISSES" ] || ! [[ "$CACHE_MISSES" =~ ^[0-9]+$ ]] && CACHE_MISSES=0
          TOTAL_HITS=$((DIRECT_HITS + PREPROCESSED_HITS))
          TOTAL_CALLS=$((TOTAL_HITS + CACHE_MISSES))
          CACHE_SIZE=$(du -sh "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "N/A")
          CACHE_SIZE_BYTES=$(du -s "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "0")
          FILE_COUNT=$(find "$CCACHE_DIR" -type f 2>/dev/null | wc -l || echo "0")
          if [ "${{ steps.cache-ccache-restore.outputs.cache-hit }}" = "true" ]; then
            CACHE_STATUS="✅ Exact match"
          elif [ -n "${{ steps.cache-ccache-restore.outputs.cache-matched-key }}" ]; then
            CACHE_STATUS="🔄 Partial match"
          else
            CACHE_STATUS="❌ Cold start"
          fi
          echo "CACHE_HIT_RATE=$CACHE_HIT_RATE" >> "$GITHUB_ENV"
          echo "CACHE_SIZE=$CACHE_SIZE" >> "$GITHUB_ENV"
          echo "CACHE_SIZE_BYTES=$CACHE_SIZE_BYTES" >> "$GITHUB_ENV"
          echo "CACHE_STATUS=$CACHE_STATUS" >> "$GITHUB_ENV"
          echo "TOTAL_HITS=$TOTAL_HITS" >> "$GITHUB_ENV"
          echo "CACHE_MISSES=$CACHE_MISSES" >> "$GITHUB_ENV"
          echo "TOTAL_CALLS=$TOTAL_CALLS" >> "$GITHUB_ENV"
          echo "FILE_COUNT=$FILE_COUNT" >> "$GITHUB_ENV"
          echo "Cache Performance:"
          echo "   Status: $CACHE_STATUS"
          echo "   Hit Rate: $CACHE_HIT_RATE%"
          echo "   Hits: $TOTAL_HITS"
          echo "   Misses: $CACHE_MISSES"
          echo "   Total Calls: $TOTAL_CALLS"
          echo "   Cache Size: $CACHE_SIZE"
          echo "   File Count: $FILE_COUNT"

      - name: Check Ccache Before Save
        id: ccache-present
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          CCACHE_DIR="${{ env.CCACHE_DIR }}"
          if [ ! -d "$CCACHE_DIR" ]; then
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "Cache dir missing"
            exit 0
          fi
          SIZE=$(du -s "$CCACHE_DIR" 2>/dev/null | awk '{print $1}' || echo "0")
          FILE_COUNT=$(find "$CCACHE_DIR" -type f 2>/dev/null | wc -l || echo "0")
          MIN_SIZE=1024
          MIN_FILES=10
          if [ "$SIZE" -gt "$MIN_SIZE" ] && [ "$FILE_COUNT" -gt "$MIN_FILES" ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "Cache has content, will save"
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "Cache is empty or too small, skip save"
          fi

      - name: Check Prebuilts Before Save
        id: prebuilts-present
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          ROOT="${{ matrix.model }}/kernel_platform"
          D1="$ROOT/prebuilts"
          D2="$ROOT/prebuilts-master"
          present=false
          for d in "$D1" "$D2"; do
            if [ -d "$d" ] && find "$d" -type f -print -quit | grep -q .; then
              echo "✅ $d has content"
              present=true
            else
              echo "ℹ️ $d missing or empty"
            fi
          done
          if [ "$present" = true ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Save Compiler Cache
        if: always() && steps.ccache-present.outputs.present == 'true' && steps.cache-ccache-restore.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ${{ steps.cache-keys.outputs.ccache_save_key }}

      - name: Save Prebuilts Cache
        if: always() && steps.prebuilts-present.outputs.present == 'true' && steps.cache-prebuilts-restore.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: |
            ${{ matrix.model }}/kernel_platform/prebuilts
            ${{ matrix.model }}/kernel_platform/prebuilts-master
          key: ${{ steps.cache-keys.outputs.prebuilts_key }}

      - name: Build Summary
        if: always()
        shell: bash
        run: |
          status="${{ job.status }}"
          [ "$status" = "success" ] && emoji="✅" || emoji="❌"
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## $emoji ${{ matrix.model }} - $status

          | Property | Value |
          |----------|-------|
          | Kernel | ${{ steps.build.outputs.kernel_version }} |
          | SukiSU | ${{ steps.build.outputs.sukisu_version }} |
          | SUSFS | ${{ steps.build.outputs.susfs_version }} |
          | Warnings | ${{ steps.build.outputs.warnings_count }} |
          | Package | \`${{ steps.build.outputs.zip_name }}\` |
          | Size | $(numfmt --to=iec-i --suffix=B ${{ steps.build.outputs.zip_size }} 2>/dev/null || echo "${{ steps.build.outputs.zip_size }}") |

          Config: Hook=\`${{ inputs.hook }}\` LSM=\`${{ inputs.lsm }}\` ZRAM=\`${{ inputs.enable_zram }}\` Opt=\`${{ inputs.optimize_level }}\`

          ### Cache Performance

          #### Keys
          - Restore: \`${{ steps.cache-keys.outputs.ccache_restore_key }}\`
          - Save: \`${{ steps.cache-keys.outputs.ccache_save_key }}\`

          #### Restore
          - Status: ${{ env.CACHE_STATUS }}
          - Matched: \`${{ steps.cache-ccache-restore.outputs.cache-matched-key || 'none' }}\`

          #### Build Statistics
          - Hit Rate: ${{ env.CACHE_HIT_RATE }}%
          - Hits: ${{ env.TOTAL_HITS }}
          - Misses: ${{ env.CACHE_MISSES }}
          - Total: ${{ env.TOTAL_CALLS }}
          - Size: ${{ env.CACHE_SIZE }}
          - Files: ${{ env.FILE_COUNT }}

          #### Save
          - Ccache: $([ "${{ steps.cache-ccache-restore.outputs.cache-hit }}" = "true" ] && echo "⏭️ Skipped (exact hit)" || ([ "${{ steps.ccache-present.outputs.present }}" = "true" ] && echo "✅ Saved to \`${{ steps.cache-keys.outputs.ccache_save_key }}\`" || echo "⏭️ Skipped (empty/small)"))
          - Prebuilts: $([ "${{ steps.cache-prebuilts-restore.outputs.cache-hit }}" = "true" ] && echo "⏭️ Skipped (exact hit)" || ([ "${{ steps.prebuilts-present.outputs.present }}" = "true" ] && echo "✅ Saved" || echo "⏭️ Skipped (empty)"))
          EOF

      - name: Upload Artifacts
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: kernel-${{ matrix.model }}-${{ matrix.android_version }}-${{ matrix.kernel_version }}
          path: ${{ matrix.model }}/artifacts/${{ steps.build.outputs.zip_name }}
          retention-days: 7
          compression-level: 0
          if-no-files-found: error

      - name: Cleanup on Cancel
        if: cancelled()
        shell: bash
        run: |
          echo "::warning::Build cancelled for ${{ matrix.model }}"
          rm -rf "${{ matrix.model }}/artifacts" "${{ matrix.model }}/out" "${{ matrix.model }}/downloads" || true
          if [ -d "${{ matrix.model }}/kernel_platform" ]; then
            find "${{ matrix.model }}/kernel_platform" -mindepth 1 -maxdepth 1 \
              ! -name "prebuilts" ! -name "prebuilts-master" \
              -exec rm -rf {} + 2>/dev/null || true
          fi
          echo "Cleanup completed (cache preserved)"

  release:
    needs: build
    runs-on: ubuntu-latest
    if: ${{ inputs.make_release }}
    permissions:
      contents: write
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      RELEASE_NAME: 'OnePlus Kernels - SukiSU Ultra & SUSFS v1.5.2+'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Required Tools
        shell: bash
        run: |
          echo "::group::Installing tools"
          sudo apt-get update -qq
          sudo apt-get install -y -qq jq unzip
          echo "::endgroup::"
          jq --version
          unzip -v | head -2

      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./all-artifacts
          merge-multiple: false
        continue-on-error: false

      - name: Assert Artifacts Downloaded
        shell: bash
        run: |
          echo "::group::Validating artifact download"
          if [ ! -d ./all-artifacts ] || ! find ./all-artifacts -type f -print -quit | grep -q .; then
            echo "::error::No artifacts were downloaded from the build job"
            exit 1
          fi
          echo "Artifacts directory exists and contains files"
          echo "::endgroup::"

      - name: List Downloaded Artifacts
        shell: bash
        run: |
          echo "::group::Downloaded Artifacts Structure"
          artifact_dirs=$(find ./all-artifacts -mindepth 1 -maxdepth 1 -type d 2>/dev/null | wc -l | tr -d '[:space:]')
          zip_count=$(find ./all-artifacts -type f -name "*.zip" 2>/dev/null | wc -l | tr -d '[:space:]')
          echo "Summary:"
          echo "  - Artifact directories: $artifact_dirs"
          echo "  - ZIP files: $zip_count"
          if [ "$artifact_dirs" -gt 0 ]; then ls -la ./all-artifacts; fi
          if [ "$zip_count" -gt 0 ]; then
            find ./all-artifacts -type f -name "*.zip" | head -50
          fi
          echo "::endgroup::"

      - name: Check gh CLI
        shell: bash
        run: |
          gh --version || { echo "::error::GitHub CLI (gh) not found on runner"; exit 1; }

      - name: Generate Tag
        shell: bash
        run: |
          set -euo pipefail
          BASE_VERSION="v1.5.2"
          echo "::group::Fetching existing releases"
          LATEST=$(gh release list \
            --repo "${{ github.repository }}" \
            --limit 300 \
            --json tagName \
            --jq '[.[] | select(.tagName | startswith("'"$BASE_VERSION"'-r")) | .tagName] | sort_by(split("-r")[1] | tonumber) | .[-1]' \
            2>/dev/null || echo "")
          echo "::endgroup::"
          if [ -z "$LATEST" ]; then
            NEW_TAG="${BASE_VERSION}-r0"
            echo "No existing tags found, starting with: $NEW_TAG"
          else
            REV=$(echo "$LATEST" | sed -n 's/.*-r\([0-9]\+\)$/\1/p')
            [ -z "$REV" ] && { echo "::error::Failed to parse revision from: $LATEST"; exit 1; }
            NEW_TAG="${BASE_VERSION}-r$((REV + 1))"
            echo "Latest tag: $LATEST (rev $REV)"
            echo "New tag: $NEW_TAG"
          fi
          echo "NEW_TAG=$NEW_TAG" >> "$GITHUB_ENV"
          if [[ "$NEW_TAG" =~ (alpha|beta|rc|test|dev|pre) ]]; then
            echo "IS_PRERELEASE=true" >> "$GITHUB_ENV"
          else
            echo "IS_PRERELEASE=false" >> "$GITHUB_ENV"
          fi
          echo "Tag to be created: $NEW_TAG"

      - name: Organize Assets
        shell: bash
        run: |
          set -euo pipefail
          
          echo "::group::Organizing Artifacts"
          
          mkdir -p ./release-assets
          
          # Copy all ZIP files with original names
          zip_count=0
          while IFS= read -r zip; do
            [ -f "$zip" ] || continue
            filename=$(basename "$zip")
            cp "$zip" "./release-assets/$filename"
            echo "✓ Copied: $filename"
            ((zip_count++))
          done < <(find ./all-artifacts -type f -name "*.zip" 2>/dev/null)
          
          echo "::endgroup::"
          
          if [ "$zip_count" -eq 0 ]; then
            echo "::error::No ZIP files were found!"
            echo ""
            echo "Debug info:"
            echo "all-artifacts exists: $([ -d ./all-artifacts ] && echo 'yes' || echo 'no')"
            echo "all-artifacts contents:"
            ls -la ./all-artifacts/ 2>/dev/null || echo "Directory not found"
            exit 1
          fi
          
          echo ""
          echo "✅ Organized $zip_count ZIP file(s)"
          echo ""
          echo "Final assets:"
          ls -lh ./release-assets/

      - name: Extract Build Info from ZIPs
        shell: bash
        run: |
          set -euo pipefail
          
          echo "::group::Extracting Build Information"
          
          # Create temporary directory for extraction
          mkdir -p ./temp-extract
          
          declare -A device_info
          
          for zip in ./release-assets/*.zip; do
            [ -f "$zip" ] || continue
            
            filename=$(basename "$zip")
            echo "Processing: $filename"
            
            # Extract model from filename
            if [[ "$filename" =~ ^([^_]+)_ ]]; then
              model="${BASH_REMATCH[1]}"
            else
              model="Unknown"
            fi
            
            # Try to extract version info from ZIP contents
            temp_dir="./temp-extract/${model}"
            mkdir -p "$temp_dir"
            
            # Extract only specific files for info
            unzip -q -o "$zip" -d "$temp_dir" "*.prop" "*.txt" 2>/dev/null || true
            
            # Try to find kernel version
            kernel_ver="Unknown"
            if [ -f "$temp_dir/version" ]; then
              kernel_ver=$(cat "$temp_dir/version" | head -1)
            elif [ -f "$temp_dir/Image.gz-dtb" ]; then
              # Could extract from kernel image if needed
              kernel_ver="Embedded"
            fi
            
            # Store info
            device_info["$model"]="$kernel_ver"
            
            echo "  Model: $model"
            echo "  Kernel: $kernel_ver"
          done
          
          # Clean up temp
          rm -rf ./temp-extract
          
          echo "::endgroup::"
          
          # Export for use in release notes
          {
            echo "DEVICE_INFO<<EOF"
            for model in "${!device_info[@]}"; do
              echo "$model|${device_info[$model]}"
            done
            echo "EOF"
          } >> "$GITHUB_ENV"

      - name: Generate Release Notes
        shell: bash
        run: |
          set -euo pipefail
          cat << 'EOF' > notes.md
          # SukiSU Ultra with SUSFS v1.5.2+

          SUSFS Module: https://github.com/sidex15/susfs4ksu-module (v1.5.2+ branch)
          SukiSU Manager: https://github.com/SukiSU-Ultra/SukiSU-Ultra
          SUSFS Kernel: https://gitlab.com/simonpunk/susfs4ksu

          ## Built Devices
          | Device | Kernel | Status |
          |--------|--------|--------|
          EOF
          
          device_count=0
          for zip in ./release-assets/*.zip; do
            [ -f "$zip" ] || continue
            
            filename=$(basename "$zip")
            
            # Extract model from filename
            if [[ "$filename" =~ ^([^_]+)_ ]]; then
              model="${BASH_REMATCH[1]}"
            else
              model="Unknown"
            fi
            
            # Extract kernel version from filename if present
            if [[ "$filename" =~ _([0-9]+\.[0-9]+) ]]; then
              kernel_ver="${BASH_REMATCH[1]}"
            else
              kernel_ver="See ZIP"
            fi
            
            # Check if SUSFS module is in ZIP
            if unzip -l "$zip" 2>/dev/null | grep -q "ksu_module_susfs"; then
              status="✅"
            else
              status="⚠️"
            fi
            
            printf "| %-12s | %-18s | %s |\n" \
              "$model" "$kernel_ver" "$status" >> notes.md
            ((device_count++))
          done
          
          if [ "$device_count" -eq 0 ]; then
            echo "| No builds completed | - | ❌ |" >> notes.md
          fi
          
          cat << 'EOF' >> notes.md

          ## Features
          - SukiSU Ultra Manager (susfs-main branch)
          - SUSFS v1.5.2+ (Kernel patches + KSU module)
          - Magic Mount support
          - WireGuard VPN support
          - BBR TCP congestion control
          - Ptrace fix for kernels <5.16
          - Flexible hook types (Manual/Kprobe/Tracepoint)
          - ZRAM with advanced compressors (LZ4K, LZ4KD, 842)
          - BBG LSM (Baseband Guard)
          - Optimized builds (O2/O3)

          ## What's Included
          - Kernel Image with SukiSU Ultra & SUSFS patches
          - SUSFS KSU Module (v1.5.2+ from CI)
          - AnyKernel3 flasher
          - Tools and scripts

          ## Installation
          1. Download the AnyKernel3 ZIP for your device
          2. Flash via Kernel Flasher or SukiSU Ultra Manager
          3. Reboot
          4. Verify SUSFS is active:
             su -c "dmesg | grep -i susfs"

          ## Legend
          - ✅ = SUSFS module confirmed in package
          - ⚠️ = SUSFS module missing

          ---
          Build Date: $(date -u '+%Y-%m-%d %H:%M UTC')
          Build Run: #${{ github.run_number }}
          Commit: ${{ github.sha }}
          Workflow: ${{ github.workflow }}
          EOF
          
          echo "Generated release notes for $device_count device(s)"
          echo "::group::Release Notes Preview"
          cat notes.md
          echo "::endgroup::"

      - name: Create Release with Assets
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Preparing release"
          if [ "${{ env.IS_PRERELEASE }}" = "true" ]; then
            PRERELEASE_FLAG="--prerelease"
          else
            PRERELEASE_FLAG="--latest"
          fi
          ASSETS=()
          while IFS= read -r -d '' file; do
            ASSETS+=("$file")
          done < <(find ./release-assets -type f -name "*.zip" -print0 2>/dev/null | sort -z)
          [ ${#ASSETS[@]} -eq 0 ] && { echo "::error::No assets found to upload!"; exit 1; }
          echo "Found ${#ASSETS[@]} asset(s) to upload:"
          printf '  - %s\n' "${ASSETS[@]}"
          echo "::endgroup::"
          for attempt in 1 2 3; do
            echo "::group::Attempt $attempt/3: Creating release ${{ env.NEW_TAG }}"
            if gh release create "${{ env.NEW_TAG }}" \
              --repo "${{ github.repository }}" \
              --title "${{ env.RELEASE_NAME }} (${{ env.NEW_TAG }})" \
              --notes-file notes.md \
              --target "${{ github.sha }}" \
              $PRERELEASE_FLAG \
              "${ASSETS[@]}"; then
              echo "::endgroup::"
              echo "Release created successfully"
              exit 0
            fi
            echo "::endgroup::"
            echo "Attempt $attempt failed"
            if [ $attempt -lt 3 ]; then
              sleep_time=$(( (RANDOM % (attempt * 5)) + attempt * 3 ))
              echo "Retrying in ${sleep_time}s..."
              sleep $sleep_time
            fi
          done
          echo "::error::Failed to create release after 3 attempts"
          exit 1

      - name: Verify Release
        if: success()
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Verifying release ${{ env.NEW_TAG }}"
          sleep 3
          RELEASE_INFO=$(gh release view "${{ env.NEW_TAG }}" \
            --repo "${{ github.repository }}" \
            --json tagName,name,url,assets,isDraft,isPrerelease,createdAt)
          ASSET_COUNT=$(echo "$RELEASE_INFO" | jq '.assets | length')
          ZIPS=$(echo "$RELEASE_INFO" | jq '[.assets[] | select(.name | endswith(".zip"))] | length')
          IS_DRAFT=$(echo "$RELEASE_INFO" | jq -r '.isDraft')
          IS_PRERELEASE=$(echo "$RELEASE_INFO" | jq -r '.isPrerelease')
          RELEASE_URL=$(echo "$RELEASE_INFO" | jq -r '.url')
          CREATED_AT=$(echo "$RELEASE_INFO" | jq -r '.createdAt')
          echo "Release Details:"
          echo "  Tag: ${{ env.NEW_TAG }}"
          echo "  URL: $RELEASE_URL"
          echo "  Total Assets: $ASSET_COUNT"
          echo "  ZIP Assets: $ZIPS"
          echo "  Draft: $IS_DRAFT"
          echo "  Prerelease: $IS_PRERELEASE"
          echo "  Created: $CREATED_AT"
          [ "$ASSET_COUNT" -eq 0 ] && { echo "::error::No assets found in release!"; exit 1; }
          [ "$ZIPS" -eq 0 ] && { echo "::error::Release has no .zip assets!"; exit 1; }
          echo "Uploaded Assets:"
          echo "$RELEASE_INFO" | jq -r '.assets[] | "  - \(.name) (\(.size | tonumber | (. / 1048576 | floor))MB)"'
          echo "::endgroup::"
          echo "Release verified successfully with $ZIPS kernel ZIP(s)!"

      - name: Release Summary
        if: always()
        shell: bash
        run: |
          status="${{ job.status }}"
          [ "$status" = "success" ] && emoji="✅" || emoji="❌"
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # $emoji Release: ${NEW_TAG:-N/A}

          Status: $status
          Type: $([ "${{ env.IS_PRERELEASE }}" = "true" ] && echo "Prerelease" || echo "Stable")
          EOF
          if [ "$status" = "success" ] && [ -n "${NEW_TAG:-}" ]; then
            echo "URL: https://github.com/${{ github.repository }}/releases/tag/$NEW_TAG" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## Assets" >> $GITHUB_STEP_SUMMARY
            gh release view "$NEW_TAG" \
              --repo "${{ github.repository }}" \
              --json assets \
              --jq '.assets[] | "- \(.name) (\((.size | tonumber) / 1048576 | floor)MB)"' \
              >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "- Could not fetch asset list" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## Release Failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            if [ -d ./release-assets ]; then
              echo "Assets that were prepared:" >> $GITHUB_STEP_SUMMARY
              find ./release-assets -name "*.zip" -type f 2>/dev/null | sort | while read -r f; do
                filename=$(basename "$f")
                size_bytes=$(stat -c%s "$f" 2>/dev/null || echo "0")
                size_mb=$((size_bytes / 1048576))
                if unzip -l "$f" 2>/dev/null | grep -q "ksu_module_susfs"; then
                  status_icon="✅"
                else
                  status_icon="⚠️"
                fi
                echo "- $status_icon $filename (${size_mb}MB)" >> $GITHUB_STEP_SUMMARY
              done || echo "- No assets found" >> $GITHUB_STEP_SUMMARY
            else
              echo "No assets were prepared (check earlier steps)" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'

          ## Configuration
          | Setting | Value |
          |---------|-------|
          | Hook | `${{ inputs.hook }}` |
          | LSM | `${{ inputs.lsm }}` |
          | ZRAM | `${{ inputs.enable_zram }}` |
          | Optimization | `${{ inputs.optimize_level }}` |

          Legend: ✅ = SUSFS module included | ⚠️ = SUSFS module missing
          EOF
